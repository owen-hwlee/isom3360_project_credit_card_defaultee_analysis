{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ISOM3360 Data Mining for Business Analytics\n",
    "## Group 23 Project Code - Credit Card Defaultee Analysis\n",
    "### Part 2.2 - Logistic Regression Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: LAM, Ho Chit  \n",
    "ITSC: hclamao   \n",
    "SID: 20607878 \n",
    "\n",
    "Name: LEE, Ho Wan Owen  \n",
    "ITSC: hwolee  \n",
    "SID: 20604852\n",
    "\n",
    "Name: LEE, Wai Chung  \n",
    "ITSC: wcleeaj  \n",
    "SID: 20702733"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow of this notebook (TBC)\n",
    "\n",
    "1. Explore features and characteristics of dataset\n",
    "2. Drop columns of low data quality (e.g. large amounts of empty values)\n",
    "3. Determine $k$ columns to keep in the dataset (feature selection)\n",
    "4. Perform one-hot encoding\n",
    "5. Split into training and testing sets\n",
    "6. Perform data cleaning\n",
    "   - Dealing with missing values\n",
    "7. Perform data standardization / normalization\n",
    "8. Export preprocessed data to .csv files at `./data_preprocessed/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "we will use all the train data (891 examples) to construct the tree and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import evaluation tools\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_clean.csv',index_col = 'PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define attributes and target variable\n",
    "features = ['Pclass','Age','SibSp','Parch','Fare','Sex_male','Embarked_Q','Embarked_S']\n",
    "target = ['Survived']\n",
    "X = train [features]\n",
    "y = train [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve and decision thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "zscore_scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_lr = pd.DataFrame(zscore_scaler.transform(X), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test.\n",
    "X_train_lr, X_test_lr, y_train, y_test = train_test_split(X_lr, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LogisticReression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the logistic regression model\n",
    "logistic_model = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# Cfloat, default=1.0. Inverse of regularization strength; must be a positive float. Smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import evaluation tools\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_score = cross_val_score(logistic_model, X_train, y_array_train, cv=10)\n",
    "print(logistic_score)\n",
    "print (logistic_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation to get the prediction\n",
    "logistic_preds = cross_val_predict(logistic_model, X_train, y_array_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'This is prediction for logistic regression: {logistic_preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_array_train, logistic_preds, normalize=True, sample_weight=None))\n",
    "print(confusion_matrix(y_array_train, logistic_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose 'predict_proba' (which gives probabilities) for the method parameter.\n",
    "# This is importat because by default cross_val_predict assumes you want to use the 'predict' method\n",
    "logistic_preds_prob = cross_val_predict(logistic_model, X_train, y_array_train, cv=10, method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preds_prob_1 = cross_val_predict(logistic_model, X_train, y_array_train, cv=10, method=\"predict_proba\")[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preds_prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase threshold for '1' to be 0.6 and get an updated prediction\n",
    "logistic_preds_prob_1_= [1 if i > 0.6 else 0 for i in logistic_preds_prob_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result after adjust the threshold\n",
    "print(confusion_matrix(y_array_train, logistic_preds_prob_1_))\n",
    "print(accuracy_score(y_array_train, logistic_preds_prob_1_, normalize=True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get false positive and true positives for each model\n",
    "logistic_fpr, logistic_tpr, thresholds = roc_curve(y_train, logistic_preds_prob_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(logistic_fpr, logistic_tpr, label=\"logistic\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AUC\n",
    "logistic_auc = auc(logistic_fpr, logistic_tpr)\n",
    "# Print results\n",
    "pd.DataFrame({\"Model\":['Logistic Regression'], \"AUC\":[logistic_auc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also use AUC as the performance measure of a grid search by including the parameter `scoring=\"roc_auc\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Search for best complexity when optimizing for AUC within DecisionTreeClassifier\n",
    "grid = {\"min_samples_leaf\":[10,25, 50, 100, 150, 200]}\n",
    "searcher = GridSearchCV(DecisionTreeClassifier(), grid, cv=10, scoring=\"roc_auc\")\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Plot result\n",
    "print(f\"Best tree min_samples_leaf: {searcher.best_params_}\")\n",
    "print(f\"Best AUC: {searcher.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for best complexity when optimizing for AUC for logistic regression\n",
    "l_grid = {\"C\": [10**i for i in np.arange(-1, 2, 0.1)]}\n",
    "l_searcher = GridSearchCV(logistic_model, l_grid, cv=10, scoring=\"roc_auc\")\n",
    "l_searcher.fit(X_train_lr, y_array_train)\n",
    "\n",
    "# Plot result\n",
    "print(f\"Best C for logsitic regression: {l_searcher.best_params_}\")\n",
    "print(f\"Best AUC: {l_searcher.best_score_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
